# 7135CEM-Modelling_and_Optimization_Under_Uncertainty
Code for MOUU module Coursework
Task 1
README - Diabetes Prediction using Machine Learning
This project evaluates five machine learning models—Gaussian Process Classifier, Logistic Regression, Random Forest, Support Vector Machine, and Gradient Boosting—for predicting diabetes risk using health indicator data. Models are compared based on accuracy, precision, recall, F1-score, AUC-ROC, and execution time. Results show that SVM and Gradient Boosting provide the highest accuracy, while Logistic Regression is the most computationally efficient. The project uses Python and Scikit-Learn for model implementation. Future improvements include hyperparameter tuning and deployment as a web application.


Task 2
Part 1
README – FLC Design for Assisted Home Common Area
This project implements a Fuzzy Logic Controller (FLC) to automate and optimize environmental and safety conditions in the common area of an assisted home. The system processes multiple sensor inputs, including patient vitals, CO2 levels, temperature, humidity, voice commands, and time, to regulate various outputs such as heating, ventilation, lighting, alarms, and accessibility features.
Key Features:
Mamdani Fuzzy Inference Model for intuitive rule-based decision-making
Centroid Defuzzification for smooth and precise control outputs
47 Fuzzy Rules to manage temperature, safety, and comfort dynamically
Rule Activation Analysis & Control Surface Plots to validate system performance
GitHub Repository includes MATLAB implementation, fuzzy membership functions, rule definitions, and simulation results
This FLC provides a smart, adaptive, and efficient control system that enhances safety and comfort in assisted living spaces.

Task 2
Part 2
Optimization on CEC'2005 Functions
This repository contains MATLAB implementations of Genetic Algorithm (GA), Particle Swarm Optimization (PSO), and Simulated Annealing (SA) on three CEC'2005 benchmark functions:

Shifted Sphere
Shifted Rosenbrock
Rotated Hybrid Composition

Each function is tested for D=2 and D=10, with 15 independent runs per algorithm. Results include mean, standard deviation, best, and worst performance.
